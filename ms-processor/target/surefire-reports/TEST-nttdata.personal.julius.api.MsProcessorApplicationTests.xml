<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="nttdata.personal.julius.api.MsProcessorApplicationTests" time="4.907" tests="1" errors="0" skipped="0" failures="0">
  <properties>
    <property name="java.specification.version" value="21"/>
    <property name="sun.cpu.isalist" value="amd64"/>
    <property name="sun.jnu.encoding" value="Cp1252"/>
    <property name="java.class.path" value="C:\Users\isa\NTTData\ms-processor\target\test-classes;C:\Users\isa\NTTData\ms-processor\target\classes;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-web\4.0.1\spring-boot-starter-web-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-jackson\4.0.1\spring-boot-starter-jackson-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-jackson\4.0.1\spring-boot-jackson-4.0.1.jar;C:\Users\isa\.m2\repository\tools\jackson\core\jackson-databind\3.0.3\jackson-databind-3.0.3.jar;C:\Users\isa\.m2\repository\tools\jackson\core\jackson-core\3.0.3\jackson-core-3.0.3.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\4.0.1\spring-boot-starter-tomcat-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat-runtime\4.0.1\spring-boot-starter-tomcat-runtime-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-web-server\4.0.1\spring-boot-web-server-4.0.1.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\11.0.15\tomcat-embed-core-11.0.15.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\11.0.15\tomcat-embed-el-11.0.15.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\11.0.15\tomcat-embed-websocket-11.0.15.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-tomcat\4.0.1\spring-boot-tomcat-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-http-converter\4.0.1\spring-boot-http-converter-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot\4.0.1\spring-boot-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-webmvc\4.0.1\spring-boot-webmvc-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-servlet\4.0.1\spring-boot-servlet-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-webmvc\7.0.2\spring-webmvc-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\kafka\spring-kafka\4.0.1\spring-kafka-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-context\7.0.2\spring-context-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-aop\7.0.2\spring-aop-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-beans\7.0.2\spring-beans-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-expression\7.0.2\spring-expression-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-messaging\7.0.2\spring-messaging-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-tx\7.0.2\spring-tx-7.0.2.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-clients\4.1.1\kafka-clients-4.1.1.jar;C:\Users\isa\.m2\repository\com\github\luben\zstd-jni\1.5.6-10\zstd-jni-1.5.6-10.jar;C:\Users\isa\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\isa\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.7\snappy-java-1.1.10.7.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-observation\1.16.1\micrometer-observation-1.16.1.jar;C:\Users\isa\.m2\repository\org\jspecify\jspecify\1.0.0\jspecify-1.0.0.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-commons\1.16.1\micrometer-commons-1.16.1.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-starter-openfeign\5.0.0\spring-cloud-starter-openfeign-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-starter\5.0.0\spring-cloud-starter-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-context\5.0.0\spring-cloud-context-5.0.0.jar;C:\Users\isa\.m2\repository\org\bouncycastle\bcprov-jdk18on\1.81\bcprov-jdk18on-1.81.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-openfeign-core\5.0.0\spring-cloud-openfeign-core-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\4.0.1\spring-boot-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-form-spring\13.6\feign-form-spring-13.6.jar;C:\Users\isa\.m2\repository\org\apache\commons\commons-text\1.13.0\commons-text-1.13.0.jar;C:\Users\isa\.m2\repository\org\apache\commons\commons-lang3\3.19.0\commons-lang3-3.19.0.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-form\13.6\feign-form-13.6.jar;C:\Users\isa\.m2\repository\commons-fileupload\commons-fileupload\1.5\commons-fileupload-1.5.jar;C:\Users\isa\.m2\repository\org\springframework\spring-web\7.0.2\spring-web-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-commons\5.0.0\spring-cloud-commons-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-crypto\7.0.2\spring-security-crypto-7.0.2.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-core\13.6\feign-core-13.6.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-slf4j\13.6\feign-slf4j-13.6.jar;C:\Users\isa\NTTData\ms-common\target\classes;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-security\4.0.1\spring-boot-starter-security-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-security\4.0.1\spring-boot-security-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-config\7.0.2\spring-security-config-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-core\7.0.2\spring-security-core-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-web\7.0.2\spring-security-web-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-validation\4.0.1\spring-boot-starter-validation-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-validation\4.0.1\spring-boot-validation-4.0.1.jar;C:\Users\isa\.m2\repository\org\hibernate\validator\hibernate-validator\9.0.1.Final\hibernate-validator-9.0.1.Final.jar;C:\Users\isa\.m2\repository\jakarta\validation\jakarta.validation-api\3.1.1\jakarta.validation-api-3.1.1.jar;C:\Users\isa\.m2\repository\org\jboss\logging\jboss-logging\3.6.1.Final\jboss-logging-3.6.1.Final.jar;C:\Users\isa\.m2\repository\com\fasterxml\classmate\1.7.1\classmate-1.7.1.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-webmvc-ui\3.0.0\springdoc-openapi-starter-webmvc-ui-3.0.0.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-webmvc-api\3.0.0\springdoc-openapi-starter-webmvc-api-3.0.0.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-common\3.0.0\springdoc-openapi-starter-common-3.0.0.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-core-jakarta\2.2.38\swagger-core-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-annotations-jakarta\2.2.38\swagger-annotations-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-models-jakarta\2.2.38\swagger-models-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.20.1\jackson-datatype-jsr310-2.20.1.jar;C:\Users\isa\.m2\repository\org\webjars\swagger-ui\5.30.1\swagger-ui-5.30.1.jar;C:\Users\isa\.m2\repository\org\webjars\webjars-locator-lite\1.1.2\webjars-locator-lite-1.1.2.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-api\0.12.6\jjwt-api-0.12.6.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-impl\0.12.6\jjwt-impl-0.12.6.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-jackson\0.12.6\jjwt-jackson-0.12.6.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.20.1\jackson-databind-2.20.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.20\jackson-annotations-2.20.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.20.1\jackson-core-2.20.1.jar;C:\Users\isa\.m2\repository\org\projectlombok\lombok\1.18.42\lombok-1.18.42.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-test\4.0.1\spring-boot-starter-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter\4.0.1\spring-boot-starter-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-logging\4.0.1\spring-boot-starter-logging-4.0.1.jar;C:\Users\isa\.m2\repository\ch\qos\logback\logback-classic\1.5.22\logback-classic-1.5.22.jar;C:\Users\isa\.m2\repository\ch\qos\logback\logback-core\1.5.22\logback-core-1.5.22.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.25.3\log4j-to-slf4j-2.25.3.jar;C:\Users\isa\.m2\repository\org\slf4j\jul-to-slf4j\2.0.17\jul-to-slf4j-2.0.17.jar;C:\Users\isa\.m2\repository\jakarta\annotation\jakarta.annotation-api\3.0.0\jakarta.annotation-api-3.0.0.jar;C:\Users\isa\.m2\repository\org\yaml\snakeyaml\2.5\snakeyaml-2.5.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-test\4.0.1\spring-boot-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\4.0.1\spring-boot-test-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\com\jayway\jsonpath\json-path\2.10.0\json-path-2.10.0.jar;C:\Users\isa\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.4\jakarta.xml.bind-api-4.0.4.jar;C:\Users\isa\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.4\jakarta.activation-api-2.1.4.jar;C:\Users\isa\.m2\repository\net\minidev\json-smart\2.6.0\json-smart-2.6.0.jar;C:\Users\isa\.m2\repository\net\minidev\accessors-smart\2.6.0\accessors-smart-2.6.0.jar;C:\Users\isa\.m2\repository\org\ow2\asm\asm\9.7.1\asm-9.7.1.jar;C:\Users\isa\.m2\repository\org\assertj\assertj-core\3.27.6\assertj-core-3.27.6.jar;C:\Users\isa\.m2\repository\net\bytebuddy\byte-buddy\1.17.8\byte-buddy-1.17.8.jar;C:\Users\isa\.m2\repository\org\awaitility\awaitility\4.3.0\awaitility-4.3.0.jar;C:\Users\isa\.m2\repository\org\hamcrest\hamcrest\3.0\hamcrest-3.0.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter\6.0.1\junit-jupiter-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-params\6.0.1\junit-jupiter-params-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-engine\6.0.1\junit-jupiter-engine-6.0.1.jar;C:\Users\isa\.m2\repository\org\mockito\mockito-core\5.20.0\mockito-core-5.20.0.jar;C:\Users\isa\.m2\repository\net\bytebuddy\byte-buddy-agent\1.17.8\byte-buddy-agent-1.17.8.jar;C:\Users\isa\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\isa\.m2\repository\org\mockito\mockito-junit-jupiter\5.20.0\mockito-junit-jupiter-5.20.0.jar;C:\Users\isa\.m2\repository\org\skyscreamer\jsonassert\1.5.3\jsonassert-1.5.3.jar;C:\Users\isa\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-core\7.0.2\spring-core-7.0.2.jar;C:\Users\isa\.m2\repository\commons-logging\commons-logging\1.3.5\commons-logging-1.3.5.jar;C:\Users\isa\.m2\repository\org\springframework\spring-test\7.0.2\spring-test-7.0.2.jar;C:\Users\isa\.m2\repository\org\xmlunit\xmlunit-core\2.10.4\xmlunit-core-2.10.4.jar;C:\Users\isa\.m2\repository\org\springframework\kafka\spring-kafka-test\4.0.1\spring-kafka-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\slf4j\slf4j-api\2.0.17\slf4j-api-2.0.17.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-clients\4.1.1\kafka-clients-4.1.1-test.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server\4.1.1\kafka-server-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-storage\4.1.1\kafka-storage-4.1.1.jar;C:\Users\isa\.m2\repository\com\github\ben-manes\caffeine\caffeine\3.2.3\caffeine-3.2.3.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-group-coordinator\4.1.1\kafka-group-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-group-coordinator-api\4.1.1\kafka-group-coordinator-api-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-coordinator-common\4.1.1\kafka-coordinator-common-4.1.1.jar;C:\Users\isa\.m2\repository\org\hdrhistogram\HdrHistogram\2.2.2\HdrHistogram-2.2.2.jar;C:\Users\isa\.m2\repository\com\google\re2j\re2j\1.8\re2j-1.8.jar;C:\Users\isa\.m2\repository\com\dynatrace\hash4j\hash4j\0.22.0\hash4j-0.22.0.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-transaction-coordinator\4.1.1\kafka-transaction-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-raft\4.1.1\kafka-raft-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-share-coordinator\4.1.1\kafka-share-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-storage-api\4.1.1\kafka-storage-api-4.1.1.jar;C:\Users\isa\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-api\2.25.3\log4j-api-2.25.3.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-core\2.25.3\log4j-core-2.25.3.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-test-common-runtime\4.1.1\kafka-test-common-runtime-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka_2.13\4.1.1\kafka_2.13-4.1.1.jar;C:\Users\isa\.m2\repository\org\scala-lang\scala-library\2.13.16\scala-library-2.13.16.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-tools-api\4.1.1\kafka-tools-api-4.1.1.jar;C:\Users\isa\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\isa\.m2\repository\commons-validator\commons-validator\1.9.0\commons-validator-1.9.0.jar;C:\Users\isa\.m2\repository\commons-beanutils\commons-beanutils\1.9.4\commons-beanutils-1.9.4.jar;C:\Users\isa\.m2\repository\commons-digester\commons-digester\2.1\commons-digester-2.1.jar;C:\Users\isa\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.20.1\jackson-dataformat-csv-2.20.1.jar;C:\Users\isa\.m2\repository\org\bitbucket\b_c\jose4j\0.9.6\jose4j-0.9.6.jar;C:\Users\isa\.m2\repository\org\scala-lang\scala-reflect\2.13.16\scala-reflect-2.13.16.jar;C:\Users\isa\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.5\scala-logging_2.13-3.9.5.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-test-common-internal-api\4.1.1\kafka-test-common-internal-api-4.1.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.20.1\jackson-dataformat-yaml-2.20.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-metadata\4.1.1\kafka-metadata-4.1.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.20.1\jackson-datatype-jdk8-2.20.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server-common\4.1.1\kafka-server-common-4.1.1.jar;C:\Users\isa\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\isa\.m2\repository\org\pcollections\pcollections\4.0.2\pcollections-4.0.2.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server-common\4.1.1\kafka-server-common-4.1.1-test.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-streams-test-utils\4.1.1\kafka-streams-test-utils-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-streams\4.1.1\kafka-streams-4.1.1.jar;C:\Users\isa\.m2\repository\org\rocksdb\rocksdbjni\9.7.3\rocksdbjni-9.7.3.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-api\6.0.1\junit-jupiter-api-6.0.1.jar;C:\Users\isa\.m2\repository\org\opentest4j\opentest4j\1.3.0\opentest4j-1.3.0.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-commons\6.0.1\junit-platform-commons-6.0.1.jar;C:\Users\isa\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-launcher\6.0.1\junit-platform-launcher-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-engine\6.0.1\junit-platform-engine-6.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-actuator\4.0.1\spring-boot-starter-actuator-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-micrometer-metrics\4.0.1\spring-boot-starter-micrometer-metrics-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-micrometer-metrics\4.0.1\spring-boot-micrometer-metrics-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-micrometer-observation\4.0.1\spring-boot-micrometer-observation-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-actuator-autoconfigure\4.0.1\spring-boot-actuator-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-actuator\4.0.1\spring-boot-actuator-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-health\4.0.1\spring-boot-health-4.0.1.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-jakarta9\1.16.1\micrometer-jakarta9-1.16.1.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-core\1.16.1\micrometer-core-1.16.1.jar;C:\Users\isa\.m2\repository\org\latencyutils\LatencyUtils\2.0.3\LatencyUtils-2.0.3.jar;"/>
    <property name="java.vm.vendor" value="Eclipse Adoptium"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="user.variant" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="America/Sao_Paulo"/>
    <property name="org.jboss.logging.provider" value="slf4j"/>
    <property name="os.name" value="Windows 11"/>
    <property name="java.vm.specification.version" value="21"/>
    <property name="APPLICATION_NAME" value="ms-processor"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="BR"/>
    <property name="sun.boot.library.path" value="C:\Program Files\Eclipse Adoptium\jdk-21.0.9.10-hotspot\bin"/>
    <property name="sun.java.command" value="C:\Users\isa\AppData\Local\Temp\surefire3048126018909558238\surefirebooter-20260129191806083_16.jar C:\Users\isa\AppData\Local\Temp\surefire3048126018909558238 2026-01-29T19-17-49_021-jvmRun1 surefire-20260129191806083_14tmp surefire_2-20260129191806083_15tmp"/>
    <property name="jdk.debug" value="release"/>
    <property name="surefire.test.class.path" value="C:\Users\isa\NTTData\ms-processor\target\test-classes;C:\Users\isa\NTTData\ms-processor\target\classes;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-web\4.0.1\spring-boot-starter-web-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-jackson\4.0.1\spring-boot-starter-jackson-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-jackson\4.0.1\spring-boot-jackson-4.0.1.jar;C:\Users\isa\.m2\repository\tools\jackson\core\jackson-databind\3.0.3\jackson-databind-3.0.3.jar;C:\Users\isa\.m2\repository\tools\jackson\core\jackson-core\3.0.3\jackson-core-3.0.3.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\4.0.1\spring-boot-starter-tomcat-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat-runtime\4.0.1\spring-boot-starter-tomcat-runtime-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-web-server\4.0.1\spring-boot-web-server-4.0.1.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\11.0.15\tomcat-embed-core-11.0.15.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\11.0.15\tomcat-embed-el-11.0.15.jar;C:\Users\isa\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\11.0.15\tomcat-embed-websocket-11.0.15.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-tomcat\4.0.1\spring-boot-tomcat-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-http-converter\4.0.1\spring-boot-http-converter-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot\4.0.1\spring-boot-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-webmvc\4.0.1\spring-boot-webmvc-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-servlet\4.0.1\spring-boot-servlet-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-webmvc\7.0.2\spring-webmvc-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\kafka\spring-kafka\4.0.1\spring-kafka-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-context\7.0.2\spring-context-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-aop\7.0.2\spring-aop-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-beans\7.0.2\spring-beans-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-expression\7.0.2\spring-expression-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-messaging\7.0.2\spring-messaging-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\spring-tx\7.0.2\spring-tx-7.0.2.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-clients\4.1.1\kafka-clients-4.1.1.jar;C:\Users\isa\.m2\repository\com\github\luben\zstd-jni\1.5.6-10\zstd-jni-1.5.6-10.jar;C:\Users\isa\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\isa\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.7\snappy-java-1.1.10.7.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-observation\1.16.1\micrometer-observation-1.16.1.jar;C:\Users\isa\.m2\repository\org\jspecify\jspecify\1.0.0\jspecify-1.0.0.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-commons\1.16.1\micrometer-commons-1.16.1.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-starter-openfeign\5.0.0\spring-cloud-starter-openfeign-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-starter\5.0.0\spring-cloud-starter-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-context\5.0.0\spring-cloud-context-5.0.0.jar;C:\Users\isa\.m2\repository\org\bouncycastle\bcprov-jdk18on\1.81\bcprov-jdk18on-1.81.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-openfeign-core\5.0.0\spring-cloud-openfeign-core-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\4.0.1\spring-boot-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-form-spring\13.6\feign-form-spring-13.6.jar;C:\Users\isa\.m2\repository\org\apache\commons\commons-text\1.13.0\commons-text-1.13.0.jar;C:\Users\isa\.m2\repository\org\apache\commons\commons-lang3\3.19.0\commons-lang3-3.19.0.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-form\13.6\feign-form-13.6.jar;C:\Users\isa\.m2\repository\commons-fileupload\commons-fileupload\1.5\commons-fileupload-1.5.jar;C:\Users\isa\.m2\repository\org\springframework\spring-web\7.0.2\spring-web-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\cloud\spring-cloud-commons\5.0.0\spring-cloud-commons-5.0.0.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-crypto\7.0.2\spring-security-crypto-7.0.2.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-core\13.6\feign-core-13.6.jar;C:\Users\isa\.m2\repository\io\github\openfeign\feign-slf4j\13.6\feign-slf4j-13.6.jar;C:\Users\isa\NTTData\ms-common\target\classes;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-security\4.0.1\spring-boot-starter-security-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-security\4.0.1\spring-boot-security-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-config\7.0.2\spring-security-config-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-core\7.0.2\spring-security-core-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\security\spring-security-web\7.0.2\spring-security-web-7.0.2.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-validation\4.0.1\spring-boot-starter-validation-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-validation\4.0.1\spring-boot-validation-4.0.1.jar;C:\Users\isa\.m2\repository\org\hibernate\validator\hibernate-validator\9.0.1.Final\hibernate-validator-9.0.1.Final.jar;C:\Users\isa\.m2\repository\jakarta\validation\jakarta.validation-api\3.1.1\jakarta.validation-api-3.1.1.jar;C:\Users\isa\.m2\repository\org\jboss\logging\jboss-logging\3.6.1.Final\jboss-logging-3.6.1.Final.jar;C:\Users\isa\.m2\repository\com\fasterxml\classmate\1.7.1\classmate-1.7.1.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-webmvc-ui\3.0.0\springdoc-openapi-starter-webmvc-ui-3.0.0.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-webmvc-api\3.0.0\springdoc-openapi-starter-webmvc-api-3.0.0.jar;C:\Users\isa\.m2\repository\org\springdoc\springdoc-openapi-starter-common\3.0.0\springdoc-openapi-starter-common-3.0.0.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-core-jakarta\2.2.38\swagger-core-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-annotations-jakarta\2.2.38\swagger-annotations-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\io\swagger\core\v3\swagger-models-jakarta\2.2.38\swagger-models-jakarta-2.2.38.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.20.1\jackson-datatype-jsr310-2.20.1.jar;C:\Users\isa\.m2\repository\org\webjars\swagger-ui\5.30.1\swagger-ui-5.30.1.jar;C:\Users\isa\.m2\repository\org\webjars\webjars-locator-lite\1.1.2\webjars-locator-lite-1.1.2.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-api\0.12.6\jjwt-api-0.12.6.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-impl\0.12.6\jjwt-impl-0.12.6.jar;C:\Users\isa\.m2\repository\io\jsonwebtoken\jjwt-jackson\0.12.6\jjwt-jackson-0.12.6.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.20.1\jackson-databind-2.20.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.20\jackson-annotations-2.20.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.20.1\jackson-core-2.20.1.jar;C:\Users\isa\.m2\repository\org\projectlombok\lombok\1.18.42\lombok-1.18.42.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-test\4.0.1\spring-boot-starter-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter\4.0.1\spring-boot-starter-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-logging\4.0.1\spring-boot-starter-logging-4.0.1.jar;C:\Users\isa\.m2\repository\ch\qos\logback\logback-classic\1.5.22\logback-classic-1.5.22.jar;C:\Users\isa\.m2\repository\ch\qos\logback\logback-core\1.5.22\logback-core-1.5.22.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.25.3\log4j-to-slf4j-2.25.3.jar;C:\Users\isa\.m2\repository\org\slf4j\jul-to-slf4j\2.0.17\jul-to-slf4j-2.0.17.jar;C:\Users\isa\.m2\repository\jakarta\annotation\jakarta.annotation-api\3.0.0\jakarta.annotation-api-3.0.0.jar;C:\Users\isa\.m2\repository\org\yaml\snakeyaml\2.5\snakeyaml-2.5.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-test\4.0.1\spring-boot-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\4.0.1\spring-boot-test-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\com\jayway\jsonpath\json-path\2.10.0\json-path-2.10.0.jar;C:\Users\isa\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.4\jakarta.xml.bind-api-4.0.4.jar;C:\Users\isa\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.4\jakarta.activation-api-2.1.4.jar;C:\Users\isa\.m2\repository\net\minidev\json-smart\2.6.0\json-smart-2.6.0.jar;C:\Users\isa\.m2\repository\net\minidev\accessors-smart\2.6.0\accessors-smart-2.6.0.jar;C:\Users\isa\.m2\repository\org\ow2\asm\asm\9.7.1\asm-9.7.1.jar;C:\Users\isa\.m2\repository\org\assertj\assertj-core\3.27.6\assertj-core-3.27.6.jar;C:\Users\isa\.m2\repository\net\bytebuddy\byte-buddy\1.17.8\byte-buddy-1.17.8.jar;C:\Users\isa\.m2\repository\org\awaitility\awaitility\4.3.0\awaitility-4.3.0.jar;C:\Users\isa\.m2\repository\org\hamcrest\hamcrest\3.0\hamcrest-3.0.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter\6.0.1\junit-jupiter-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-params\6.0.1\junit-jupiter-params-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-engine\6.0.1\junit-jupiter-engine-6.0.1.jar;C:\Users\isa\.m2\repository\org\mockito\mockito-core\5.20.0\mockito-core-5.20.0.jar;C:\Users\isa\.m2\repository\net\bytebuddy\byte-buddy-agent\1.17.8\byte-buddy-agent-1.17.8.jar;C:\Users\isa\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\isa\.m2\repository\org\mockito\mockito-junit-jupiter\5.20.0\mockito-junit-jupiter-5.20.0.jar;C:\Users\isa\.m2\repository\org\skyscreamer\jsonassert\1.5.3\jsonassert-1.5.3.jar;C:\Users\isa\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\isa\.m2\repository\org\springframework\spring-core\7.0.2\spring-core-7.0.2.jar;C:\Users\isa\.m2\repository\commons-logging\commons-logging\1.3.5\commons-logging-1.3.5.jar;C:\Users\isa\.m2\repository\org\springframework\spring-test\7.0.2\spring-test-7.0.2.jar;C:\Users\isa\.m2\repository\org\xmlunit\xmlunit-core\2.10.4\xmlunit-core-2.10.4.jar;C:\Users\isa\.m2\repository\org\springframework\kafka\spring-kafka-test\4.0.1\spring-kafka-test-4.0.1.jar;C:\Users\isa\.m2\repository\org\slf4j\slf4j-api\2.0.17\slf4j-api-2.0.17.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-clients\4.1.1\kafka-clients-4.1.1-test.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server\4.1.1\kafka-server-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-storage\4.1.1\kafka-storage-4.1.1.jar;C:\Users\isa\.m2\repository\com\github\ben-manes\caffeine\caffeine\3.2.3\caffeine-3.2.3.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-group-coordinator\4.1.1\kafka-group-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-group-coordinator-api\4.1.1\kafka-group-coordinator-api-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-coordinator-common\4.1.1\kafka-coordinator-common-4.1.1.jar;C:\Users\isa\.m2\repository\org\hdrhistogram\HdrHistogram\2.2.2\HdrHistogram-2.2.2.jar;C:\Users\isa\.m2\repository\com\google\re2j\re2j\1.8\re2j-1.8.jar;C:\Users\isa\.m2\repository\com\dynatrace\hash4j\hash4j\0.22.0\hash4j-0.22.0.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-transaction-coordinator\4.1.1\kafka-transaction-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-raft\4.1.1\kafka-raft-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-share-coordinator\4.1.1\kafka-share-coordinator-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-storage-api\4.1.1\kafka-storage-api-4.1.1.jar;C:\Users\isa\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-api\2.25.3\log4j-api-2.25.3.jar;C:\Users\isa\.m2\repository\org\apache\logging\log4j\log4j-core\2.25.3\log4j-core-2.25.3.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-test-common-runtime\4.1.1\kafka-test-common-runtime-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka_2.13\4.1.1\kafka_2.13-4.1.1.jar;C:\Users\isa\.m2\repository\org\scala-lang\scala-library\2.13.16\scala-library-2.13.16.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-tools-api\4.1.1\kafka-tools-api-4.1.1.jar;C:\Users\isa\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\isa\.m2\repository\commons-validator\commons-validator\1.9.0\commons-validator-1.9.0.jar;C:\Users\isa\.m2\repository\commons-beanutils\commons-beanutils\1.9.4\commons-beanutils-1.9.4.jar;C:\Users\isa\.m2\repository\commons-digester\commons-digester\2.1\commons-digester-2.1.jar;C:\Users\isa\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.20.1\jackson-dataformat-csv-2.20.1.jar;C:\Users\isa\.m2\repository\org\bitbucket\b_c\jose4j\0.9.6\jose4j-0.9.6.jar;C:\Users\isa\.m2\repository\org\scala-lang\scala-reflect\2.13.16\scala-reflect-2.13.16.jar;C:\Users\isa\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.5\scala-logging_2.13-3.9.5.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-test-common-internal-api\4.1.1\kafka-test-common-internal-api-4.1.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.20.1\jackson-dataformat-yaml-2.20.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-metadata\4.1.1\kafka-metadata-4.1.1.jar;C:\Users\isa\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.20.1\jackson-datatype-jdk8-2.20.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server-common\4.1.1\kafka-server-common-4.1.1.jar;C:\Users\isa\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\isa\.m2\repository\org\pcollections\pcollections\4.0.2\pcollections-4.0.2.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-server-common\4.1.1\kafka-server-common-4.1.1-test.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-streams-test-utils\4.1.1\kafka-streams-test-utils-4.1.1.jar;C:\Users\isa\.m2\repository\org\apache\kafka\kafka-streams\4.1.1\kafka-streams-4.1.1.jar;C:\Users\isa\.m2\repository\org\rocksdb\rocksdbjni\9.7.3\rocksdbjni-9.7.3.jar;C:\Users\isa\.m2\repository\org\junit\jupiter\junit-jupiter-api\6.0.1\junit-jupiter-api-6.0.1.jar;C:\Users\isa\.m2\repository\org\opentest4j\opentest4j\1.3.0\opentest4j-1.3.0.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-commons\6.0.1\junit-platform-commons-6.0.1.jar;C:\Users\isa\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-launcher\6.0.1\junit-platform-launcher-6.0.1.jar;C:\Users\isa\.m2\repository\org\junit\platform\junit-platform-engine\6.0.1\junit-platform-engine-6.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-actuator\4.0.1\spring-boot-starter-actuator-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-starter-micrometer-metrics\4.0.1\spring-boot-starter-micrometer-metrics-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-micrometer-metrics\4.0.1\spring-boot-micrometer-metrics-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-micrometer-observation\4.0.1\spring-boot-micrometer-observation-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-actuator-autoconfigure\4.0.1\spring-boot-actuator-autoconfigure-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-actuator\4.0.1\spring-boot-actuator-4.0.1.jar;C:\Users\isa\.m2\repository\org\springframework\boot\spring-boot-health\4.0.1\spring-boot-health-4.0.1.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-jakarta9\1.16.1\micrometer-jakarta9-1.16.1.jar;C:\Users\isa\.m2\repository\io\micrometer\micrometer-core\1.16.1\micrometer-core-1.16.1.jar;C:\Users\isa\.m2\repository\org\latencyutils\LatencyUtils\2.0.3\LatencyUtils-2.0.3.jar;"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="C:\Users\isa"/>
    <property name="user.language" value="pt"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="spring.embedded.kafka.brokers" value="localhost:55706"/>
    <property name="java.version.date" value="2025-10-21"/>
    <property name="java.home" value="C:\Program Files\Eclipse Adoptium\jdk-21.0.9.10-hotspot"/>
    <property name="file.separator" value="\"/>
    <property name="basedir" value="C:\Users\isa\NTTData\ms-processor"/>
    <property name="java.vm.compressedOopsMode" value="Zero based"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="FILE_LOG_CHARSET" value="UTF-8"/>
    <property name="java.awt.headless" value="true"/>
    <property name="surefire.real.class.path" value="C:\Users\isa\AppData\Local\Temp\surefire3048126018909558238\surefirebooter-20260129191806083_16.jar"/>
    <property name="user.script" value=""/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="21.0.9+10-LTS"/>
    <property name="user.name" value="isa"/>
    <property name="stdout.encoding" value="Cp1252"/>
    <property name="path.separator" value=";"/>
    <property name="os.version" value="10.0"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.version" value="Temurin-21.0.9+10"/>
    <property name="localRepository" value="C:\Users\isa\.m2\repository"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="java.io.tmpdir" value="C:\Users\isa\AppData\Local\Temp\"/>
    <property name="java.version" value="21.0.9"/>
    <property name="spring.kafka.bootstrap-servers" value="localhost:55706"/>
    <property name="user.dir" value="C:\Users\isa\NTTData\ms-processor"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="PID" value="36800"/>
    <property name="sun.os.patch.level" value=""/>
    <property name="CONSOLE_LOG_CHARSET" value="UTF-8"/>
    <property name="native.encoding" value="Cp1252"/>
    <property name="java.library.path" value="C:\Program Files\Eclipse Adoptium\jdk-21.0.9.10-hotspot\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Users\isa\bin;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\local\bin;C:\Program Files\Git\usr\bin;C:\Program Files\Git\usr\bin;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\bin;C:\Users\isa\bin;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\bin;C:\Users\isa\bin;%JAVA_HOME%\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\WINDOWS\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;C:\Program Files\Go\bin;C:\Program Files\dotnet;C:\Program Files\nodejs;C:\Program Files\Eclipse Adoptium\jdk-21.0.9.10-hotspot\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\WINDOWS\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\Users\isa\AppData\Local\Microsoft\WindowsApps;C:\Users\isa\.claude;C:\Users\isa\.local\bin;C:\Users\isa\go\bin;C:\Users\isa\tools\apache-maven-3.9.6\bin;C:\Users\isa\AppData\Roaming\npm;C:\Program Files\Git\usr\bin\vendor_perl;C:\Program Files\Git\usr\bin\core_perl;."/>
    <property name="java.vm.info" value="mixed mode, sharing"/>
    <property name="stderr.encoding" value="Cp1252"/>
    <property name="java.vendor" value="Eclipse Adoptium"/>
    <property name="java.vm.version" value="21.0.9+10-LTS"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="65.0"/>
    <property name="LOGGED_APPLICATION_NAME" value="[ms-processor] "/>
  </properties>
  <testcase name="contextLoads" classname="nttdata.personal.julius.api.MsProcessorApplicationTests" time="0.168">
    <system-out><![CDATA[19:18:07.778 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils -- Could not detect default configuration classes for test class [nttdata.personal.julius.api.MsProcessorApplicationTests]: MsProcessorApplicationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
19:18:07.888 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper -- Found @SpringBootConfiguration nttdata.personal.julius.api.MsProcessorApplication for test class nttdata.personal.julius.api.MsProcessorApplicationTests

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v4.0.1)

2026-01-29T19:18:08.571-03:00  INFO 36800 --- [ms-processor] [           main] o.a.k.server.logger.LoggingController    : No supported logging implementation found. Logging configuration endpoint will be disabled.
2026-01-29T19:18:08.649-03:00  INFO 36800 --- [ms-processor] [           main] k.utils.Log4jControllerRegistration$     : Registered `kafka:type=kafka.Log4jController` MBean
Formatting metadata directory C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0 with metadata.version 4.2-IV1.
2026-01-29T19:18:08.975-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Starting controller
2026-01-29T19:18:08.976-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Transition from SHUTDOWN to STARTING
2026-01-29T19:18:08.979-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.SharedServer                : [SharedServer id=0] Starting SharedServer
2026-01-29T19:18:09.074-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__cluster_metadata-0, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:09.075-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__cluster_metadata-0, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Reloading from producer snapshot and rebuilding producer state from offset 0
2026-01-29T19:18:09.075-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__cluster_metadata-0, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0
2026-01-29T19:18:09.098-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.raft.KafkaMetadataLog$             : Initialized snapshots with IDs SortedSet() from C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__cluster_metadata-0
2026-01-29T19:18:09.152-03:00  INFO 36800 --- [ms-processor] [piration-reaper] ExpirationService$ExpiredOperationReaper : [raft-expiration-reaper]: Starting
2026-01-29T19:18:09.172-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Reading KRaft snapshot and log as part of the initialization
2026-01-29T19:18:09.176-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Starting voters are VoterSet(voters={0=VoterNode(voterKey=ReplicaKey(id=0, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/127.0.0.1:55705}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])})
2026-01-29T19:18:09.182-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Starting request manager with static voters: [localhost:55705 (id: 0 rack: null isFenced: false)]
2026-01-29T19:18:09.187-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1666, highWatermark=Optional.empty) from null
2026-01-29T19:18:09.209-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1666, highWatermark=Optional.empty) from null
2026-01-29T19:18:09.213-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1291, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1666, highWatermark=Optional.empty)
2026-01-29T19:18:09.214-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Attempting durable transition to CandidateState(localId=0, localDirectoryId=3bxzTNddNxwRuVIsYH0HSQ, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1853) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1291, highWatermark=Optional.empty)
2026-01-29T19:18:09.218-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Completed transition to CandidateState(localId=0, localDirectoryId=3bxzTNddNxwRuVIsYH0HSQ, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1853) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1291, highWatermark=Optional.empty)
2026-01-29T19:18:09.221-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=0, directoryId=3bxzTNddNxwRuVIsYH0HSQ), listeners=Endpoints(endpoints={}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=3bxzTNddNxwRuVIsYH0HSQ, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1853)
2026-01-29T19:18:09.224-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.raft.QuorumState        : [RaftManager id=0] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=0, directoryId=3bxzTNddNxwRuVIsYH0HSQ), listeners=Endpoints(endpoints={}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=3bxzTNddNxwRuVIsYH0HSQ, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1853)
2026-01-29T19:18:09.235-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] o.a.kafka.raft.KafkaRaftClientDriver     : [kafka-0-raft-io-thread]: Starting
2026-01-29T19:18:09.235-03:00  INFO 36800 --- [ms-processor] [-request-thread] o.a.k.r.KafkaNetworkChannel$SendThread   : [kafka-0-raft-outbound-request-thread]: Starting
2026-01-29T19:18:09.262-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet.
2026-01-29T19:18:09.263-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Starting broker
2026-01-29T19:18:09.269-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] org.apache.kafka.raft.LeaderState        : [RaftManager id=0] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)]
2026-01-29T19:18:09.280-03:00  INFO 36800 --- [ms-processor] [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [broker-0-ThrottledChannelReaper-Produce]: Starting
2026-01-29T19:18:09.280-03:00  INFO 36800 --- [ms-processor] [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [broker-0-ThrottledChannelReaper-Fetch]: Starting
2026-01-29T19:18:09.281-03:00  INFO 36800 --- [ms-processor] [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [broker-0-ThrottledChannelReaper-Request]: Starting
2026-01-29T19:18:09.281-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1883318555
2026-01-29T19:18:09.282-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@1883318555 to 0 since there are no snapshots
2026-01-29T19:18:09.282-03:00  INFO 36800 --- [ms-processor] [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [broker-0-ThrottledChannelReaper-ControllerMutation]: Starting
2026-01-29T19:18:09.286-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-01-29T19:18:09.326-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for controller quorum voters future
2026-01-29T19:18:09.326-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for controller quorum voters future
2026-01-29T19:18:09.338-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-forwarding-channel-manager]: Starting
2026-01-29T19:18:09.339-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:55705 (id: 0 rack: null isFenced: false)
2026-01-29T19:18:09.345-03:00  INFO 36800 --- [ms-processor] [-metrics-reaper] o.a.k.s.u.t.SystemTimerReaper$Reaper     : [client-metrics-reaper]: Starting
2026-01-29T19:18:09.377-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-01-29T19:18:09.417-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.network.ConnectionQuotas           : Updated connection-accept-rate max connection creation rate to 2147483647
2026-01-29T19:18:09.417-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.network.ConnectionQuotas           : Updated connection-accept-rate max connection creation rate to 2147483647
2026-01-29T19:18:09.420-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.network.DataPlaneAcceptor          : Awaiting socket connections on localhost:55706.
2026-01-29T19:18:09.420-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.network.DataPlaneAcceptor          : Awaiting socket connections on localhost:55705.
2026-01-29T19:18:09.421-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.network.DataPlaneAcceptor          : Opened wildcard endpoint localhost:55705
2026-01-29T19:18:09.421-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.network.DataPlaneAcceptor          : Opened wildcard endpoint localhost:55706
2026-01-29T19:18:09.446-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.network.SocketServer               : [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL)
2026-01-29T19:18:09.446-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.network.SocketServer               : [SocketServer listenerType=CONTROLLER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER)
2026-01-29T19:18:09.448-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] org.apache.kafka.metadata.ListenerInfo   : EXTERNAL: resolved ephemeral port to 55706
2026-01-29T19:18:09.448-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] org.apache.kafka.metadata.ListenerInfo   : CONTROLLER: resolved ephemeral port to 55705
2026-01-29T19:18:09.453-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.s.network.EndpointReadyFutures     : authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY.
2026-01-29T19:18:09.453-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Waiting for controller quorum voters future
2026-01-29T19:18:09.454-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Finished waiting for controller quorum voters future
2026-01-29T19:18:09.454-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-alter-partition-channel-manager]: Starting
2026-01-29T19:18:09.454-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:55705 (id: 0 rack: null isFenced: false)
2026-01-29T19:18:09.464-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-directory-assignments-channel-manager]: Starting
2026-01-29T19:18:09.464-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:55705 (id: 0 rack: null isFenced: false)
2026-01-29T19:18:09.482-03:00  INFO 36800 --- [ms-processor] [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Starting
2026-01-29T19:18:09.482-03:00  INFO 36800 --- [ms-processor] [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Starting
2026-01-29T19:18:09.483-03:00  INFO 36800 --- [ms-processor] [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Starting
2026-01-29T19:18:09.483-03:00  INFO 36800 --- [ms-processor] [r-0-RemoteFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteFetch]: Starting
2026-01-29T19:18:09.484-03:00  INFO 36800 --- [ms-processor] [moteListOffsets] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-RemoteListOffsets]: Starting
2026-01-29T19:18:09.485-03:00  INFO 36800 --- [ms-processor] [er-0-ShareFetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-ShareFetch]: Starting
2026-01-29T19:18:09.487-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-01-29T19:18:09.497-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task writeNoOpRecord to run every 500 ms
2026-01-29T19:18:09.498-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task maybeFenceStaleBroker to run every 1125 ms
2026-01-29T19:18:09.498-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task electPreferred to run every 300000 ms
2026-01-29T19:18:09.498-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task electUnclean to run every 300000 ms
2026-01-29T19:18:09.498-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task expireDelegationTokens to run every 3600000 ms
2026-01-29T19:18:09.499-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Registering periodic task generatePeriodicPerformanceMessage to run every 60000 ms
2026-01-29T19:18:09.501-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] o.a.kafka.controller.QuorumController    : [QuorumController id=0] Creating new QuorumController with clusterId wjot9fzbQmeoIC_IWsxuYw
2026-01-29T19:18:09.501-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@378000794
2026-01-29T19:18:09.501-03:00  INFO 36800 --- [ms-processor] [-raft-io-thread] org.apache.kafka.raft.KafkaRaftClient    : [RaftManager id=0] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@378000794 to 0 since there are no snapshots
2026-01-29T19:18:09.502-03:00  INFO 36800 --- [ms-processor] [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [controller-0-ThrottledChannelReaper-Fetch]: Starting
2026-01-29T19:18:09.502-03:00  INFO 36800 --- [ms-processor] [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [controller-0-ThrottledChannelReaper-Produce]: Starting
2026-01-29T19:18:09.502-03:00  INFO 36800 --- [ms-processor] [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [controller-0-ThrottledChannelReaper-Request]: Starting
2026-01-29T19:18:09.502-03:00  INFO 36800 --- [ms-processor] [trollerMutation] lientQuotaManager$ThrottledChannelReaper : [controller-0-ThrottledChannelReaper-ControllerMutation]: Starting
2026-01-29T19:18:09.503-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.kafka.controller.QuorumController    : [QuorumController id=0] Becoming the active controller at epoch 1, next write offset 1.
2026-01-29T19:18:09.513-03:00  INFO 36800 --- [ms-processor] [rdinator-reaper] o.a.k.s.u.t.SystemTimerReaper$Reaper     : [share-coordinator-reaper]: Starting
2026-01-29T19:18:09.515-03:00  WARN 36800 --- [ms-processor] [0-event-handler] o.a.kafka.controller.QuorumController    : [QuorumController id=0] Performing controller activation. The metadata log appears to be empty. Appending 6 bootstrap record(s) in metadata transaction at metadata.version 4.2-IV1 from bootstrap source 'testkit'.
2026-01-29T19:18:09.519-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.OffsetControlManager    : [QuorumController id=0] Replayed BeginTransactionRecord(name='Bootstrap records') at offset 1.
2026-01-29T19:18:09.519-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting metadata.version to 4.2-IV1
2026-01-29T19:18:09.520-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting feature eligible.leader.replicas.version to 1
2026-01-29T19:18:09.520-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting feature group.version to 1
2026-01-29T19:18:09.521-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting feature share.version to 1
2026-01-29T19:18:09.521-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting feature streams.version to 1
2026-01-29T19:18:09.521-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.FeatureControlManager   : [QuorumController id=0] Replayed a FeatureLevelRecord setting feature transaction.version to 2
2026-01-29T19:18:09.521-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ConfigurationControlManager      : [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=BROKER, name='') which set configuration min.insync.replicas to 1
2026-01-29T19:18:09.521-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.OffsetControlManager    : [QuorumController id=0] Replayed EndTransactionRecord() at offset 9.
2026-01-29T19:18:09.522-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.PeriodicTaskControlManager       : [QuorumController id=0] Activated periodic tasks: electPreferred, electUnclean, expireDelegationTokens, generatePeriodicPerformanceMessage, maybeFenceStaleBroker, writeNoOpRecord
2026-01-29T19:18:09.526-03:00  INFO 36800 --- [ms-processor] [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Starting
2026-01-29T19:18:09.536-03:00  INFO 36800 --- [ms-processor] [ent-processor-0] eadedEventProcessor$EventProcessorThread : [share-coordinator-event-processor-0]: Starting
2026-01-29T19:18:09.540-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Waiting for the controller metadata publishers to be installed
2026-01-29T19:18:09.540-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Finished waiting for the controller metadata publishers to be installed
2026-01-29T19:18:09.540-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-01-29T19:18:09.540-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.network.SocketServer               : [SocketServer listenerType=CONTROLLER, nodeId=0] Enabling request processing.
2026-01-29T19:18:09.547-03:00  INFO 36800 --- [ms-processor] [-manager-reaper] o.a.k.s.u.t.SystemTimerReaper$Reaper     : [persister-state-manager-reaper]: Starting
2026-01-29T19:18:09.547-03:00  INFO 36800 --- [ms-processor] [terStateManager] k.s.s.p.PersisterStateManager$SendThread : [PersisterStateManager]: Starting
2026-01-29T19:18:09.548-03:00  INFO 36800 --- [ms-processor] [rdinator-reaper] o.a.k.s.u.t.SystemTimerReaper$Reaper     : [group-coordinator-reaper]: Starting
2026-01-29T19:18:09.559-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [controller-0-to-controller-registration-channel-manager]: Starting
2026-01-29T19:18:09.559-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [controller-0-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:55705 (id: 0 rack: null isFenced: false)
2026-01-29T19:18:09.560-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.server.ControllerRegistrationManager   : [ControllerRegistrationManager id=0 incarnation=jX-QIoonRQ2RazWvNvfFmQ] initialized channel manager.
2026-01-29T19:18:09.560-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.server.ControllerRegistrationManager   : [ControllerRegistrationManager id=0 incarnation=jX-QIoonRQ2RazWvNvfFmQ] maybeSendControllerRegistration: cannot register yet because the metadata.version is not known yet.
2026-01-29T19:18:09.563-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 10
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Waiting for all of the authorizer futures to be completed
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Finished waiting for all of the authorizer futures to be completed
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-3] kafka.server.ControllerServer            : [ControllerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ent-processor-0] eadedEventProcessor$EventProcessorThread : [group-coordinator-event-processor-0]: Starting
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ent-processor-1] eadedEventProcessor$EventProcessorThread : [group-coordinator-event-processor-1]: Starting
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ent-processor-2] eadedEventProcessor$EventProcessorThread : [group-coordinator-event-processor-2]: Starting
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [ent-processor-3] eadedEventProcessor$EventProcessorThread : [group-coordinator-event-processor-3]: Starting
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 9
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 9
2026-01-29T19:18:09.565-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 9
2026-01-29T19:18:09.569-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.m.publisher.FeaturesPublisher      : [ControllerServer id=0] Loaded new metadata FinalizedFeatures[metadataVersion=4.2-IV1, finalizedFeatures={group.version=1, streams.version=1, transaction.version=2, eligible.leader.replicas.version=1, share.version=1, metadata.version=29}, finalizedFeaturesEpoch=9].
2026-01-29T19:18:09.569-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 9
2026-01-29T19:18:09.569-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 9
2026-01-29T19:18:09.570-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.580-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.s.metadata.DynamicConfigPublisher      : [DynamicConfigPublisher controller id=0] Updating cluster configuration : min.insync.replicas -> 1
2026-01-29T19:18:09.583-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.server.ControllerRegistrationManager   : [ControllerRegistrationManager id=0 incarnation=jX-QIoonRQ2RazWvNvfFmQ] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=0, incarnationId=jX-QIoonRQ2RazWvNvfFmQ, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='localhost', port=55705, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=29), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='streams.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)])
2026-01-29T19:18:09.587-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.common.config.AbstractConfig   : KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@localhost:55705]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = EXTERNAL
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = EXTERNAL://localhost:0,CONTROLLER://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 600000
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true

2026-01-29T19:18:09.596-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.log.LogManager                     : Unable to read the broker epoch in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0.
2026-01-29T19:18:09.597-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.598-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-heartbeat-channel-manager]: Starting
2026-01-29T19:18:09.598-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.NodeToControllerRequestThread   : [broker-0-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:55705 (id: 0 rack: null isFenced: false)
2026-01-29T19:18:09.603-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.604-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing ScramPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.607-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.BrokerLifecycleManager      : [BrokerLifecycleManager id=0] Incarnation rceqGxpzR4a4ST7bBs3J3g of broker 0 in cluster wjot9fzbQmeoIC_IWsxuYw is now STARTING.
2026-01-29T19:18:09.608-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.613-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 9
2026-01-29T19:18:09.614-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing AclPublisher controller id=0 with a snapshot at offset 9
2026-01-29T19:18:09.630-03:00  INFO 36800 --- [ms-processor] [-timeout-reaper] o.a.k.s.u.t.SystemTimerReaper$Reaper     : [share-group-lock-timeout-reaper]: Starting
2026-01-29T19:18:09.641-03:00  INFO 36800 --- [ms-processor] [per-0-AlterAcls] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-AlterAcls]: Starting
2026-01-29T19:18:09.665-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for the broker metadata publishers to be installed
2026-01-29T19:18:09.665-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for the broker metadata publishers to be installed
2026-01-29T19:18:09.665-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for the controller to acknowledge that we are caught up
2026-01-29T19:18:09.666-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing MetadataVersionPublisher(id=0) with a snapshot at offset 9
2026-01-29T19:18:09.666-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 9
2026-01-29T19:18:09.668-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.s.metadata.BrokerMetadataPublisher     : [BrokerMetadataPublisher id=0] Publishing initial metadata at offset OffsetAndEpoch[offset=9, epoch=1] with metadata.version Optional[4.2-IV1].
2026-01-29T19:18:09.669-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Loading logs from log dirs ArrayBuffer(C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0)
2026-01-29T19:18:09.676-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : No logs found to be loaded in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
2026-01-29T19:18:09.684-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.ClusterControlManager   : [QuorumController id=0] Replayed RegisterControllerRecord containing ControllerRegistration(id=0, incarnationId=jX-QIoonRQ2RazWvNvfFmQ, zkMigrationReady=false, listeners=[Endpoint(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='localhost', port=55705)], supportedFeatures={eligible.leader.replicas.version: 0-1, group.version: 0-1, kraft.version: 0-1, metadata.version: 7-29, share.version: 0-1, streams.version: 0-1, transaction.version: 0-2}).
2026-01-29T19:18:09.686-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Loaded 0 logs in 16ms
2026-01-29T19:18:09.687-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2026-01-29T19:18:09.687-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2026-01-29T19:18:09.692-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.ClusterControlManager   : [QuorumController id=0] No previous registration found for broker 0. New incarnation ID is rceqGxpzR4a4ST7bBs3J3g.  Generated 0 record(s) to clean up previous incarnations. New broker epoch is 11.
2026-01-29T19:18:09.696-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.LogCleaner   : Starting the log cleaner
2026-01-29T19:18:09.701-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.ClusterControlManager   : [QuorumController id=0] Replayed initial RegisterBrokerRecord for broker 0: RegisterBrokerRecord(brokerId=0, isMigratingZkBroker=false, incarnationId=rceqGxpzR4a4ST7bBs3J3g, brokerEpoch=11, endPoints=[BrokerEndpoint(name='EXTERNAL', host='localhost', port=55706, securityProtocol=0)], features=[BrokerFeature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=29), BrokerFeature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='streams.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), BrokerFeature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[1YnCLFwp6zSskb8uJQEVuw])
2026-01-29T19:18:09.703-03:00  INFO 36800 --- [ms-processor] [leaner-thread-0] o.a.k.s.i.log.LogCleaner$CleanerThread   : [kafka-log-cleaner-thread-0]: Starting
2026-01-29T19:18:09.706-03:00  INFO 36800 --- [ms-processor] [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2026-01-29T19:18:09.707-03:00  INFO 36800 --- [ms-processor] [nSenderThread-0] o.a.k.s.t.AddPartitionsToTxnManager      : [AddPartitionsToTxnSenderThread-0]: Starting
2026-01-29T19:18:09.710-03:00  INFO 36800 --- [ms-processor] [channel-manager] k.server.ControllerRegistrationManager   : [ControllerRegistrationManager id=0 incarnation=jX-QIoonRQ2RazWvNvfFmQ] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest.
2026-01-29T19:18:09.712-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.c.group.GroupCoordinatorService    : [GroupCoordinator id=0] Starting up.
2026-01-29T19:18:09.712-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.BrokerLifecycleManager      : [BrokerLifecycleManager id=0] Successfully registered broker 0 with broker epoch 11
2026-01-29T19:18:09.715-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.c.group.GroupCoordinatorService    : [GroupCoordinator id=0] Startup complete.
2026-01-29T19:18:09.716-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Starting up.
2026-01-29T19:18:09.718-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Startup complete.
2026-01-29T19:18:09.718-03:00  INFO 36800 --- [ms-processor] [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [TxnMarkerSenderThread-0]: Starting
2026-01-29T19:18:09.719-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.c.share.ShareCoordinatorService    : [ShareCoordinator id=0] Starting up.
2026-01-29T19:18:09.719-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.c.share.ShareCoordinatorService    : [ShareCoordinator id=0] Startup complete.
2026-01-29T19:18:09.732-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.s.metadata.DynamicConfigPublisher      : [DynamicConfigPublisher broker id=0] Updating cluster configuration : min.insync.replicas -> 1
2026-01-29T19:18:09.733-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.common.config.AbstractConfig   : KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@localhost:55705]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = EXTERNAL
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = EXTERNAL://localhost:0,CONTROLLER://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 600000
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true

2026-01-29T19:18:09.741-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.s.metadata.BrokerMetadataPublisher     : [BrokerMetadataPublisher id=0] Feature share.version has been updated to version 1
2026-01-29T19:18:09.741-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.kafka.image.loader.MetadataLoader    : [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=0) with a snapshot at offset 9
2026-01-29T19:18:09.743-03:00  INFO 36800 --- [ms-processor] [r-event-handler] k.server.ControllerRegistrationManager   : [ControllerRegistrationManager id=0 incarnation=jX-QIoonRQ2RazWvNvfFmQ] Our registration has been persisted to the metadata log.
2026-01-29T19:18:09.751-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.BrokerLifecycleManager      : [BrokerLifecycleManager id=0] The broker has caught up. Transitioning from STARTING to RECOVERY.
2026-01-29T19:18:09.751-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for the controller to acknowledge that we are caught up
2026-01-29T19:18:09.751-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for the initial broker metadata update to be published
2026-01-29T19:18:09.751-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for the initial broker metadata update to be published
2026-01-29T19:18:09.752-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] o.a.kafka.common.config.AbstractConfig   : KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@localhost:55705]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = EXTERNAL
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = EXTERNAL://localhost:0,CONTROLLER://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 600000
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = true
	unstable.feature.versions.enable = true

2026-01-29T19:18:09.753-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for the broker to be unfenced
2026-01-29T19:18:09.755-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.BrokerHeartbeatManager  : [QuorumController id=0] The request from broker 0 to unfence has been granted because it has caught up with the offset of its register broker record 11.
2026-01-29T19:18:09.759-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.controller.ClusterControlManager   : [QuorumController id=0] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 0: BrokerRegistrationChangeRecord(brokerId=0, brokerEpoch=11, fenced=-1, inControlledShutdown=0, logDirs=[])
2026-01-29T19:18:09.798-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.BrokerLifecycleManager      : [BrokerLifecycleManager id=0] The broker has been unfenced. Transitioning from RECOVERY to RUNNING.
2026-01-29T19:18:09.798-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for the broker to be unfenced
2026-01-29T19:18:09.798-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] o.a.k.s.network.EndpointReadyFutures     : authorizerStart completed for endpoint EXTERNAL. Endpoint is now READY.
2026-01-29T19:18:09.798-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.network.SocketServer               : [SocketServer listenerType=BROKER, nodeId=0] Enabling request processing.
2026-01-29T19:18:09.799-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for all of the authorizer futures to be completed
2026-01-29T19:18:09.799-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for all of the authorizer futures to be completed
2026-01-29T19:18:09.799-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2026-01-29T19:18:09.799-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2026-01-29T19:18:09.799-03:00  INFO 36800 --- [ms-processor] [ster-test-kit-4] kafka.server.BrokerServer                : [BrokerServer id=0] Transition from STARTING to STARTED
2026-01-29T19:18:09.806-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.config.AbstractConfig   : AdminClientConfig values: 
	bootstrap.controllers = []
	bootstrap.servers = [localhost:55706]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = rebootstrap
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2026-01-29T19:18:09.826-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
2026-01-29T19:18:09.826-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
2026-01-29T19:18:09.826-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1769725089826
2026-01-29T19:18:09.859-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='transaction-events', numPartitions=1, replicationFactor=1, assignments=[], configs=[]): SUCCESS
2026-01-29T19:18:09.860-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed TopicRecord for topic transaction-events with topic ID NXT7qkjXQZS6NKNIsPDsEQ.
2026-01-29T19:18:09.863-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition transaction-events-0 with topic ID NXT7qkjXQZS6NKNIsPDsEQ and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:09.894-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Transitioning 1 partition(s) to local leaders.
2026-01-29T19:18:09.895-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(transaction-events-0)
2026-01-29T19:18:09.896-03:00  INFO 36800 --- [ms-processor] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2026-01-29T19:18:09.896-03:00  INFO 36800 --- [ms-processor] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2026-01-29T19:18:09.896-03:00  INFO 36800 --- [ms-processor] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2026-01-29T19:18:09.896-03:00  INFO 36800 --- [ms-processor] [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
2026-01-29T19:18:09.897-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition transaction-events-0 with topic id NXT7qkjXQZS6NKNIsPDsEQ.
2026-01-29T19:18:09.899-03:00  INFO 36800 --- [ms-processor] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2026-01-29T19:18:09.899-03:00  INFO 36800 --- [ms-processor] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2026-01-29T19:18:09.899-03:00  INFO 36800 --- [ms-processor] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2026-01-29T19:18:09.915-03:00  INFO 36800 --- [ms-processor] [           main] n.p.j.api.MsProcessorApplicationTests    : Starting MsProcessorApplicationTests using Java 21.0.9 with PID 36800 (started by isa in C:\Users\isa\NTTData\ms-processor)
2026-01-29T19:18:09.915-03:00 DEBUG 36800 --- [ms-processor] [           main] n.p.j.api.MsProcessorApplicationTests    : Running with Spring Boot v4.0.1, Spring v7.0.2
2026-01-29T19:18:09.916-03:00  INFO 36800 --- [ms-processor] [           main] n.p.j.api.MsProcessorApplicationTests    : The following 1 profile is active: "test"
2026-01-29T19:18:09.918-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=transaction-events-0, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:09.921-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition transaction-events-0 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\transaction-events-0 with properties {}
2026-01-29T19:18:09.922-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition transaction-events-0 broker=0] No checkpointed highwatermark is found for partition transaction-events-0
2026-01-29T19:18:09.923-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition transaction-events-0 broker=0] Log loaded for partition transaction-events-0 with initial high watermark 0
2026-01-29T19:18:09.930-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader transaction-events-0 with topic id Some(NXT7qkjXQZS6NKNIsPDsEQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:10.901-03:00  INFO 36800 --- [ms-processor] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=a0ab06a3-f108-34d2-8b8c-52abd6be19ea
2026-01-29T19:18:11.839-03:00  WARN 36800 --- [ms-processor] [           main] .s.a.UserDetailsServiceAutoConfiguration : 

Using generated security password: c6534b4a-482c-440d-9b84-fcb3e53155e2

This generated password is for development use only. Your security configuration must be updated before running your application in production.

2026-01-29T19:18:11.865-03:00  INFO 36800 --- [ms-processor] [           main] r$InitializeUserDetailsManagerConfigurer : Global AuthenticationManager configured with UserDetailsService bean with name inMemoryUserDetailsManager
2026-01-29T19:18:12.010-03:00  INFO 36800 --- [ms-processor] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
2026-01-29T19:18:12.258-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:55706]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-processor-group-test-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = processor-group-test
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = rebootstrap
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	share.acknowledgement.mode = implicit
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2026-01-29T19:18:12.282-03:00  INFO 36800 --- [ms-processor] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2026-01-29T19:18:12.320-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
2026-01-29T19:18:12.321-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
2026-01-29T19:18:12.321-03:00  INFO 36800 --- [ms-processor] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1769725092320
2026-01-29T19:18:12.322-03:00  INFO 36800 --- [ms-processor] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Subscribed to topic(s): transaction-events
2026-01-29T19:18:12.338-03:00  INFO 36800 --- [ms-processor] [           main] n.p.j.api.MsProcessorApplicationTests    : Started MsProcessorApplicationTests in 4.144 seconds (process running for 6.211)
2026-01-29T19:18:12.352-03:00  WARN 36800 --- [ms-processor] [           main] o.s.core.events.SpringDocAppInitializer  : SpringDoc /v3/api-docs endpoint is enabled by default. To disable it in production, set the property 'springdoc.api-docs.enabled=false'
2026-01-29T19:18:12.352-03:00  WARN 36800 --- [ms-processor] [           main] o.s.core.events.SpringDocAppInitializer  : SpringDoc /swagger-ui.html endpoint is enabled by default. To disable it in production, set the property 'springdoc.swagger-ui.enabled=false'
2026-01-29T19:18:12.360-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Cluster ID: wjot9fzbQmeoIC_IWsxuYw
2026-01-29T19:18:12.360-03:00  INFO 36800 --- [ms-processor] [quest-handler-5] k.s.DefaultAutoTopicCreationManager      : Sent auto-creation request for Set(__consumer_offsets) to the active controller.
2026-01-29T19:18:12.364-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]): SUCCESS
2026-01-29T19:18:12.364-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed TopicRecord for topic __consumer_offsets with topic ID R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ConfigurationControlManager      : [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ConfigurationControlManager      : [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ConfigurationControlManager      : [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.365-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.366-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.367-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.368-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.368-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.368-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.368-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.368-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.369-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.370-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.370-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.370-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.371-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.371-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.371-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.371-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.371-03:00  INFO 36800 --- [ms-processor] [0-event-handler] o.a.k.c.ReplicationControlManager        : [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID R6A-mpKqSrKv7R0sFk4plw and PartitionRegistration(replicas=[0], directories=[1YnCLFwp6zSskb8uJQEVuw], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-01-29T19:18:12.397-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Transitioning 50 partition(s) to local leaders.
2026-01-29T19:18:12.397-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2)
2026-01-29T19:18:12.397-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-13 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.409-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-13, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.410-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-13 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.410-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13
2026-01-29T19:18:12.410-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0
2026-01-29T19:18:12.410-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-13 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.413-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-46 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.418-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-46, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.418-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-46 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.418-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46
2026-01-29T19:18:12.418-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0
2026-01-29T19:18:12.418-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-46 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.421-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-9 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.426-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-9, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.427-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-9 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.427-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9
2026-01-29T19:18:12.427-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0
2026-01-29T19:18:12.428-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-9 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.431-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-42 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.436-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-42, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.437-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-42 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.438-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42
2026-01-29T19:18:12.438-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0
2026-01-29T19:18:12.438-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-42 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.440-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-21 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.446-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-21, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.447-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-21 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.447-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21
2026-01-29T19:18:12.447-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0
2026-01-29T19:18:12.447-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-21 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.451-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-17 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.468-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-17, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.469-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-17 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.470-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17
2026-01-29T19:18:12.470-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0
2026-01-29T19:18:12.470-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-17 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.472-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-30 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.474-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Discovered group coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false)
2026-01-29T19:18:12.476-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] (Re-)joining group
2026-01-29T19:18:12.492-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-30, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.493-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-30 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.493-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30
2026-01-29T19:18:12.494-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0
2026-01-29T19:18:12.494-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-30 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.496-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-26 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.503-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-26, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.505-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-26 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.505-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26
2026-01-29T19:18:12.505-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0
2026-01-29T19:18:12.506-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-26 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.509-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-5 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.511-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Group coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
2026-01-29T19:18:12.511-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Requesting disconnect from last known coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false)
2026-01-29T19:18:12.512-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
2026-01-29T19:18:12.512-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Client requested disconnect from node 2147483647
2026-01-29T19:18:12.515-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-5, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-5 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Discovered group coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false)
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Group coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-processor-group-test-1, groupId=processor-group-test] Requesting disconnect from last known coordinator localhost:55706 (id: 2147483647 rack: null isFenced: false)
2026-01-29T19:18:12.516-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-5 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.519-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-38 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.525-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-38, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.525-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-38 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.525-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38
2026-01-29T19:18:12.525-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0
2026-01-29T19:18:12.525-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-38 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-01-29T19:18:12.529-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Creating new partition __consumer_offsets-1 with topic id R6A-mpKqSrKv7R0sFk4plw.
2026-01-29T19:18:12.534-03:00  INFO 36800 --- [ms-processor] [r-event-handler] o.a.k.storage.internals.log.UnifiedLog   : [LogLoader partition=__consumer_offsets-1, dir=C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0] Loading producer state till offset 0
2026-01-29T19:18:12.534-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\isa\AppData\Local\Temp\kafka-17372133619427575320\combined_0_0\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-01-29T19:18:12.534-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2026-01-29T19:18:12.534-03:00  INFO 36800 --- [ms-processor] [r-event-handler] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2026-01-29T19:18:12.536-03:00  INFO 36800 --- [ms-processor] [r-event-handler] state.change.logger                      : [Broker id=0] Leader __consumer_offsets-1 with topic id Some(R6A-mpKqSrKv7R0sFk4plw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
]]></system-out>
  </testcase>
</testsuite>